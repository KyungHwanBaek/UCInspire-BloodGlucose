{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df15138f-8646-4a83-968e-649e29511791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch, numpy as np\\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\\nfrom torch.nn import MSELoss\\nfrom model import FKAN \\n\\npsi = torch.load(\"psi_T1.pt\") \\nY = np.load(\"Y_T1.npy\")\\nY_mean = np.load(\"Y_mean.npy\")\\nY_std  = np.load(\"Y_std.npy\")\\nYn = (Y - Y_mean) / (Y_std + 1e-6)\\nYt = torch.tensor(Yn, dtype=torch.float32)\\n\\nds = TensorDataset(psi, Yt)\\ntrain_len = int(0.8 * len(ds))\\nval_len = len(ds) - train_len\\ntrain_ds, val_ds = random_split(ds, [train_len, val_len])\\n\\ntrain_loader = DataLoader(train_ds, batch_size=1024, shuffle=True, pin_memory=True)\\nval_loader   = DataLoader(val_ds,   batch_size=1024, shuffle=False, pin_memory=True)\\n\\ndevice= \"cuda\" if torch.cuda.is_available() else \"cpu\"\\nin_dim  = psi.shape[1]\\nout_dim = Yt.shape[1]\\nmodel = FKAN(in_dim, hid_feats=64, out_feats=out_dim, G=5).to(device)\\n\\nopt  = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-4)\\ncrit = MSELoss()\\nbest, wait, patience = 1e9, 0, 5\\n\\nfor epoch in range(1, 101):\\n    model.train(); tr_loss = 0\\n    for xb, yb in train_loader:\\n        xb, yb = xb.to(device), yb.to(device)\\n        opt.zero_grad()\\n        loss = crit(model(xb), yb)\\n        loss.backward()\\n        opt.step()\\n        tr_loss += loss.item() * xb.size(0)\\n    tr_loss /= len(train_loader.dataset)\\n\\n    model.eval(); va_loss = 0\\n    with torch.no_grad():\\n        for xb, yb in val_loader:\\n            xb, yb = xb.to(device), yb.to(device)\\n            va_loss += crit(model(xb), yb).item() * xb.size(0)\\n    va_loss /= len(val_loader.dataset)\\n\\n    print(f\"[{epoch:03d}] train={tr_loss:.4f}  val={va_loss:.4f}\")\\n\\n    if va_loss < best - 1e-4:\\n        best, wait = va_loss, 0\\n        torch.save(model.state_dict(), \"best_sugarnet.pt\")\\n        print(\"  ✔️  saved best_sugarnet.pt\")\\n    else:\\n        wait += 1\\n        if wait >= patience:\\n            print(\"⏹️  Early stop\"); break\\n\\nprint(\"BEST val MSE:\", best)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.nn import MSELoss\n",
    "from model import FKAN \n",
    "\n",
    "psi = torch.load(\"psi_T1.pt\") \n",
    "Y = np.load(\"Y_T1.npy\")\n",
    "Y_mean = np.load(\"Y_mean.npy\")\n",
    "Y_std  = np.load(\"Y_std.npy\")\n",
    "Yn = (Y - Y_mean) / (Y_std + 1e-6)\n",
    "Yt = torch.tensor(Yn, dtype=torch.float32)\n",
    "\n",
    "ds = TensorDataset(psi, Yt)\n",
    "train_len = int(0.8 * len(ds))\n",
    "val_len = len(ds) - train_len\n",
    "train_ds, val_ds = random_split(ds, [train_len, val_len])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=1024, shuffle=True, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=1024, shuffle=False, pin_memory=True)\n",
    "\n",
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "in_dim  = psi.shape[1]\n",
    "out_dim = Yt.shape[1]\n",
    "model = FKAN(in_dim, hid_feats=64, out_feats=out_dim, G=5).to(device)\n",
    "\n",
    "opt  = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-4)\n",
    "crit = MSELoss()\n",
    "best, wait, patience = 1e9, 0, 5\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    model.train(); tr_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        loss = crit(model(xb), yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tr_loss += loss.item() * xb.size(0)\n",
    "    tr_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval(); va_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            va_loss += crit(model(xb), yb).item() * xb.size(0)\n",
    "    va_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"[{epoch:03d}] train={tr_loss:.4f}  val={va_loss:.4f}\")\n",
    "\n",
    "    if va_loss < best - 1e-4:\n",
    "        best, wait = va_loss, 0\n",
    "        torch.save(model.state_dict(), \"best_sugarnet.pt\")\n",
    "        print(\"  ✔️  saved best_sugarnet.pt\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"⏹️  Early stop\"); break\n",
    "\n",
    "print(\"BEST val MSE:\", best)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eda9473-8de3-46e3-b0a8-007c2b805e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] train_loss=0.3588  val_loss=0.3628\n",
      "Saved best_fkan.pt\n",
      "[02] train_loss=0.3585  val_loss=0.3624\n",
      "Saved best_fkan.pt\n",
      "[03] train_loss=0.3578  val_loss=0.3615\n",
      "Saved best_fkan.pt\n",
      "[04] train_loss=0.3565  val_loss=0.3595\n",
      "Saved best_fkan.pt\n",
      "[05] train_loss=0.3547  val_loss=0.3580\n",
      "Saved best_fkan.pt\n",
      "[06] train_loss=0.3530  val_loss=0.3563\n",
      "Saved best_fkan.pt\n",
      "[07] train_loss=0.3511  val_loss=0.3533\n",
      "Saved best_fkan.pt\n",
      "[08] train_loss=0.3493  val_loss=0.3529\n",
      "Saved best_fkan.pt\n",
      "[09] train_loss=0.3477  val_loss=0.3507\n",
      "Saved best_fkan.pt\n",
      "[10] train_loss=0.3455  val_loss=0.3476\n",
      "Saved best_fkan.pt\n",
      "[11] train_loss=0.3430  val_loss=0.3466\n",
      "Saved best_fkan.pt\n",
      "[12] train_loss=0.3410  val_loss=0.3461\n",
      "Saved best_fkan.pt\n",
      "[13] train_loss=0.3390  val_loss=0.3439\n",
      "Saved best_fkan.pt\n",
      "[14] train_loss=0.3367  val_loss=0.3407\n",
      "Saved best_fkan.pt\n",
      "[15] train_loss=0.3352  val_loss=0.3411\n",
      "[16] train_loss=0.3328  val_loss=0.3388\n",
      "Saved best_fkan.pt\n",
      "[17] train_loss=0.3306  val_loss=0.3372\n",
      "Saved best_fkan.pt\n",
      "[18] train_loss=0.3291  val_loss=0.3352\n",
      "Saved best_fkan.pt\n",
      "[19] train_loss=0.3273  val_loss=0.3348\n",
      "Saved best_fkan.pt\n",
      "[20] train_loss=0.3260  val_loss=0.3341\n",
      "Saved best_fkan.pt\n",
      "[21] train_loss=0.3239  val_loss=0.3320\n",
      "Saved best_fkan.pt\n",
      "[22] train_loss=0.3234  val_loss=0.3335\n",
      "[23] train_loss=0.3216  val_loss=0.3297\n",
      "Saved best_fkan.pt\n",
      "[24] train_loss=0.3198  val_loss=0.3272\n",
      "Saved best_fkan.pt\n",
      "[25] train_loss=0.3176  val_loss=0.3264\n",
      "Saved best_fkan.pt\n",
      "[26] train_loss=0.3165  val_loss=0.3287\n",
      "[27] train_loss=0.3143  val_loss=0.3274\n",
      "[28] train_loss=0.3142  val_loss=0.3269\n",
      "[29] train_loss=0.3110  val_loss=0.3249\n",
      "Saved best_fkan.pt\n",
      "[30] train_loss=0.3107  val_loss=0.3250\n",
      "[31] train_loss=0.3077  val_loss=0.3234\n",
      "Saved best_fkan.pt\n",
      "[32] train_loss=0.3073  val_loss=0.3221\n",
      "Saved best_fkan.pt\n",
      "[33] train_loss=0.3057  val_loss=0.3205\n",
      "Saved best_fkan.pt\n",
      "[34] train_loss=0.3062  val_loss=0.3195\n",
      "Saved best_fkan.pt\n",
      "[35] train_loss=0.3029  val_loss=0.3217\n",
      "[36] train_loss=0.3016  val_loss=0.3203\n",
      "[37] train_loss=0.3009  val_loss=0.3204\n",
      "[38] train_loss=0.2991  val_loss=0.3174\n",
      "Saved best_fkan.pt\n",
      "[39] train_loss=0.2989  val_loss=0.3153\n",
      "Saved best_fkan.pt\n",
      "[40] train_loss=0.2975  val_loss=0.3158\n",
      "[41] train_loss=0.2943  val_loss=0.3194\n",
      "[42] train_loss=0.2955  val_loss=0.3140\n",
      "Saved best_fkan.pt\n",
      "[43] train_loss=0.2943  val_loss=0.3172\n",
      "[44] train_loss=0.2922  val_loss=0.3110\n",
      "Saved best_fkan.pt\n",
      "[45] train_loss=0.2925  val_loss=0.3136\n",
      "[46] train_loss=0.2909  val_loss=0.3091\n",
      "Saved best_fkan.pt\n",
      "[47] train_loss=0.2890  val_loss=0.3122\n",
      "[48] train_loss=0.2882  val_loss=0.3094\n",
      "[49] train_loss=0.2880  val_loss=0.3100\n",
      "[50] train_loss=0.2852  val_loss=0.3129\n",
      "Best validation loss: 0.3091\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.nn import SmoothL1Loss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from model import FKAN\n",
    "\n",
    "T = 288\n",
    "LOW_K = int(T * 0.10)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(2025)\n",
    "np.random.seed(2025)\n",
    "\n",
    "def vectorize(gamma: torch.Tensor) -> torch.Tensor:\n",
    "    B, K = gamma.shape\n",
    "    k = (K - 1) // 2\n",
    "    R0 = gamma[:, :1]\n",
    "    R = gamma[:, 1 : k+1]\n",
    "    I = gamma[:, k+1 : ]\n",
    "    half = torch.complex(R, I)\n",
    "    conj_half = torch.conj(torch.flip(half[:, 1:], dims=[1]))\n",
    "    full_spec = torch.cat([R0, half, conj_half], dim=1)\n",
    "    return torch.fft.ifft(full_spec, n=T).real\n",
    "\n",
    "psi = torch.load(\"psi_T1.pt\")\n",
    "Y = np.load(\"Y_T1.npy\")\n",
    "Y_mean = np.load(\"Y_mean.npy\")\n",
    "Y_std = np.load(\"Y_std.npy\")\n",
    "Yn = (Y - Y_mean) / (Y_std + 1e-6)\n",
    "Yt = torch.tensor(Yn, dtype=torch.float32)\n",
    "target_dim = Yt.shape[1]\n",
    "\n",
    "ds = TensorDataset(psi, Yt)\n",
    "n_tr = int(0.8 * len(ds))\n",
    "train_ds, val_ds = random_split(ds, [n_tr, len(ds)-n_tr])\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=256, shuffle=False, pin_memory=True, num_workers=2)\n",
    "\n",
    "in_feats = psi.shape[1]\n",
    "freq_feats = 1 + 2 * LOW_K\n",
    "model = FKAN(in_feats, hid_feats=128, out_feats=freq_feats, G=5).to(DEVICE)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "sched = ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3)\n",
    "crit = SmoothL1Loss()\n",
    "\n",
    "best_val = float('inf')\n",
    "wait = 0\n",
    "patience = 5\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    model.train()\n",
    "    tr_loss = 0.0\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        gamma_pred = model(x)\n",
    "        y_pred = vectorize(gamma_pred)[:, :target_dim]\n",
    "        loss = crit(y_pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tr_loss += loss.item() * x.size(0)\n",
    "    tr_loss /= len(train_ds)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            gamma_pred = model(x)\n",
    "            y_pred = vectorize(gamma_pred)[:, :target_dim]\n",
    "            val_loss += crit(y_pred, y).item() * x.size(0)\n",
    "    val_loss /= len(val_ds)\n",
    "    sched.step(val_loss)\n",
    "    print(f\"[{epoch:02d}] train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}\")\n",
    "    if val_loss < best_val - 1e-4:\n",
    "        best_val = val_loss\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), \"best_fkan.pt\")\n",
    "        print(\"Saved best_fkan.pt\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(f\"Best validation loss: {best_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7995786-931c-428f-a8b0-6850dc5535d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (efficient-kan-KyungHwan)",
   "language": "python",
   "name": "efficient-kan-kyunghwan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
